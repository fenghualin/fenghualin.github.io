[{"title":"多线程总结","date":"2018-04-09T00:44:52.000Z","path":"2018/04/09/多线程总结/","text":"多线程的由来&emsp;&emsp;世界上第一台通用计算机“ENIAC”于1946年在美国宾夕法尼亚大学诞生，还未出现操作系统，计算机工作采用手工操作方式。程序员将对应于程序和数据的已穿孔的纸带装入输入机，然后启动输入机把程序和数据输入计算机内存，接着通过控制台开关启动程序针对数据运行；计算完毕，打印机输出计算结果；用户取走结果并卸下纸带后，才让下一个用户上机。数据的输入、程序的启动、结果的输出都需要手工控制，并且只能线性作业，手工速度和CPU的高速运算形成了尖锐矛盾，严重浪费了宝贵的计算机资源。&emsp;&emsp;为了解决这个问题，第一代计算机管理控制程序（操作系统）应运而生，这就是批处理操作系统，它在主机与输入机之间增加一个存储设备——磁带，在批处理操作系统的控制下，计算机可自动成批地把输入机上的用户作业读入磁带，依次把磁带上的用户作业读入主机内存并执行并把计算结果向输出机输出。完成了上一批作业后，又从输入机上输入另一批作业，保存在磁带上，并按上述步骤重复处理。随着外围输入输出设备的发展，cpu的速度不断提高，操作系统也不断的发展,后面出现了分时操作系统、实时操作系统、个人计算机操作系统。&emsp;&emsp;计算机的心脏是CPU，它承担了所有计算任务；而操作系统是计算机的管理者，他负责任务的调度、资源的分配和管理；应用程序则是运行于操作系统之上。一个正在操作系统上运行的程序就是一个进程，进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。 在早期的操作系统中并没有线程的概念，随着计算机的发展，对CPU的要求越来越高，进程之间的切换开销较大，已经无法满足越来越复杂的程序的要求了，于是创造出了线程。线程是程序执行中一个单一的顺序控制流程，是程序执行流的最小单元，是处理器调度和分派的基本单位。一个进程可以有一个或多个线程，各个线程之间共享程序的内存空间。一个标准的线程由线程ID、当前指令指针（pc）、寄存器和堆栈组成。而进程由内存空间（代码、数据、进程空间、打开的文件）和一个或多个线程组成。所以线程的切换比进程快很多，操作系统通过线程能高效的分配cpu片段给各个程序。 多线程的问题&emsp;&emsp;多线程技术充分利用了cpu资源，提高了程序的效率。但是，多线程也带来了线程安全、多线程程序复杂、大量线程需要消耗很多系统资源等问题。 线程安全&emsp;&emsp;什么是线程安全问题，当存在两个或者两个以上的线程对象共享同一个资源，共享数据存在被并发修改的可能，那么就会出现线程安全问题。解决线程安全问题可以从以下几个方面思考：&emsp;&emsp;1. 消除共享变量：把全局变量变为局部变量，局部变量存放在栈，线程间不共享，就不存在线程安全问题了。消除共享数据的不足：如果需要一个对象采集各个线程的信息，或者在线程间传递信息，消除了共享变量就不可行了。&emsp;&emsp;2. 使用线程同步机制：给读写操作同时加锁，使得同时只有一个线程可以访问共享数据。是同时给读写加锁，还是只给写加锁，根据具体需求而定。同步机制的缺点是降低了程序的吞吐量。&emsp;&emsp;3. 采用并发数据结构：java jdk提供了并发的数据结构api，如CopyOnWriteArrayList、CopyOnWriteArraySet、ConcurrentLinkedQueue等。&emsp;&emsp;4. 建立副本：使用ThreadLocal为每一个线程建立一个变量的副本，各个线程间独立操作，互不影响。 线程死锁&emsp;&emsp;多线程编程中，通过加锁来解决线程安全问题的同时，也会带来死锁。为了避免死锁，我们首先弄清楚产生死锁的原因。&emsp;&emsp;所谓死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。产生死锁必须同时满足以下四个条件，只要其中任一条件不成立，死锁就不会发生。&emsp;&emsp;1. 互斥条件：线程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个线程所占有。此时若有其他线程请求该资源，则请求线程只能等待。&emsp;&emsp;2. 不剥夺条件：线程所获得的资源在未使用完毕之前，不能被其他线程强行夺走，即只能由获得该资源的线程自己来释放（只能是主动释放)。&emsp;&emsp;3. 请求和保持条件：线程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他线程占有，此时请求线程被阻塞，但对自己已获得的资源保持不放。&emsp;&emsp;4. 循环等待条件：存在一种程资源的循环等待链，链中每一个线程已获得的资源同时被链中下一个线程所请求。若干个线程组成了环路，该环路中每一个线程都在等待着相邻的线程占据的资源。 线程阻塞、异步编程&emsp;&emsp;线程在执行中如果遇到I/O 操作（如磁盘读写或网络通信），通常要耗费较长的时间，这时操作系统会剥夺这个线程的 CPU 控制权，使其暂停执行，同时将资源让给其他的工作线程。当 I/O 操作完毕时，操作系统将这个线程的阻塞状态解除，恢复其对CPU的控制权，令其继续执行。这种 I/O 模式就是通常的阻塞式 I/O（Blocking I/O）。阻塞模式下，一个线程只能处理一项任务，要想提高吞吐量必须通过不断的增加线程。增加线程要不断消耗系统资源，一定会很快耗尽系统资源。比如，BIO 的sockect服务，一个线程处理一个请求，即使使用了线程池技术，并发量也是有限的。&emsp;&emsp;阻塞I/O也叫同步I/O，与之对应的是非阻塞I/O也叫异步I/O。 异步I/O操作时，不会以阻塞的方式等待I/O操作的完成或数据的返回，而只是将 I/O 请求发送给操作系统，继续执行下一条语句。当操作系统完成I/O操作时，以事件的形式通知执行I/O操作的线程，线程会在特定时候处理这个事件。nginx和node.js处理并发都是采用的事件驱动异步非阻塞模式,所以他们在大并发的http请求处理上表现非常牛逼。&emsp;&emsp;异步主要应用于I/O操作，数据库访问，磁盘操作，Socket访问、HTTP/TCP网络通信，对于IO操作并不需要CPU进行计算，这些数据主要通过磁盘进行处理，如果进行同步操作，需要创建更多的线程，大量创建线程和线程上下文的切换会大量消耗计算机资源，针对I/O操作不需要单独的分配一个线程来处理。异步操作无须额外的线程负担，并且使用回调的方式进行处理，在设计良好的情况下，处理函数可以不必使用共享变量，减少了死锁的可能。","tags":[{"name":"java","slug":"java","permalink":"https://fenghualin.github.io/tags/java/"},{"name":"多线程","slug":"多线程","permalink":"https://fenghualin.github.io/tags/多线程/"}]},{"title":"关于设计模式的理解","date":"2018-03-26T07:23:31.000Z","path":"2018/03/26/关于设计模式的理解/","text":"&emsp;&emsp;我记得在2010年左右设计模式火爆的时候，那时候程序员的简历上面必须写上熟悉设计模式，也是面试官必问的题目。最近发现找工作的，招人的不怎么提设计模式了，都是讲人工智能、微服务、大数据、区块链等。我想2010年左右Java这样的面向对象的语言的普及使用，面向对象的设计方法正好是设计模式的最佳实践。也许到现在面向对象的设计已经普及，不在是新的技能了，随着各个行业的互联网巨头的发展，人工智能、大数据、微服务等就成了现在的IT技术人员学习的方向了，你要是不简历上面写点大数据、分布式的技术（hadoop、zookeeper、hive、spark…）、人工智能（tensorflow、python…)、微服务（dubbo、spring cloud）这些框架的使用，基本很难找到互联网公司工作。&emsp;&emsp;那是不是因为这么多年的发展，已经有了大量的软件人才了，基本的软件开发编程技能都已经精通熟练了呢，所以基础基本不用太关心了，会用新的技术、新的框架你就能做好软件了呢。显然不是这样的，框架不能帮你完成所有的系统设计和开发、具体的业务还是需要分析设计、编码去实现。没有好的基本功，很难设计出好的系统、写出易于维护和扩展的代码。&emsp;&emsp;今天有时间我又回顾了下设计模式方面的东西,把一些感想写下来。 设计模式起源&emsp;&emsp;‘模式’这个概念，最早是在建筑领域出现，建筑在人类历史有几千年的底蕴，人们总结和积累了很多经验教训。哈佛大学的建筑学博士克里斯托弗.亚历山大，是建筑学领域的模式之父。他的团队总结出了253个模式。软件工程却只有几十年的历史，软件领域的大师们也对软件工程总结出了软件的设计模式。1995年， GoF将收集和整理好的23种设计模式写成了《设计模式》一书、标志着设计模式的诞生。 设计模式介绍&emsp;&emsp;设计模式（Design pattern）代表了最佳的实践，通常被有经验的面向对象的软件开发人员所采用。设计模式是软件开发人员在软件开发过程中面临的一般问题的解决方案。这些解决方案是众多软件开发人员经过相当长的一段时间的试验和错误总结出来的。&emsp;&emsp;看看上面这段教科书式的定义，是不是我们看了还是一脸懵逼。即使你把Gof那一本《设计模式》看完，可能你也很难在系统开发中用上设计模式。把23个模式的定义背下来，开发的时候套上去，真可能弄巧成拙，画虎类犬。&emsp;&emsp;那怎样才能正确理解设计模式和运用好他呢，我认为需要搞清楚我们为什么用设计模式，设计模式的目的，设计模式有什么准则。&emsp;&emsp;应对变化、大家普遍认为设计模式是为了软件的复用，利于他人理解。我觉得这个不是设计模式的根本核心，只要你写的代码清晰，就算是面向过程编程也可以做到。 软件开发中最不好应付的是‘变化’，任何事物都是在变化的，软件也是一个生命体，他要成长要变化。所以好的软件编码是能适应成长变化的（可以理解为系统的不断升级、需求的不断变化）。设计模式就是解决怎么优雅的应对这些变化，比如：设计模式里面的创建型模式就是封装对象创建的变化。&emsp;&emsp;设计模式准则、这里的设计模式准则也可以说是面向对象设计的准则，Gof总结的23个设计模式，基本围绕面向对象设计的六个准则实现。理解掌握了六个准则，才能融会贯通各个设计模式，运用自如。 单一职责原则&emsp;&emsp;单一职责原则，简单的说就是一个类只负责一件事情。很多人说这个原则太简单，但是请不要小看这个准则，这个准则本质也是优雅的应对变化，软件开发中我们经常会出现修改一个功能，影响了其他功能。避免出现这一问题的方法便是遵循单一职责原则。这个原则的把握也是需要你的经验积累，不只是类要单一职责，你的类里面的方法、更高层次的模块等都需要遵循。 里氏替换原则&emsp;&emsp;里氏替换原则，第一次看见这个原则真的感觉这个名字怪怪的，看名字是不知道啥意思了，这项原则最早是在1988年，由麻省理工学院的一位姓里的女士（Barbara Liskov）提出来的，我们的软件大师们就取了个这么的名字。那名字定了就也不好改了，就这样叫吧。看看具体的里氏替换原则的定义：任何基类可以出现的地方，子类一定可以出现。&emsp;&emsp;当使用继承时，需要遵循里氏替换原则。继承做为现代面向对象语言三大特性之一，给面向对象编程提供了基础，但是继承使用不好也会带来灾难。父类已经实现好的方法，如果子类对这些非抽象方法任意修改，就会对整个继承体系造成破坏，父类出现的地方，子类出现就有问题了，子类改变了父类的这个行为。也就是说，子类可以扩展父类的功能，但不能改变父类原有的功能。所以我们在使用继承的时候不要覆盖父类的非抽象方法，也最好不要重载父类的方法。&emsp;&emsp;在实际开发过程中，我们常常会直接重写父类的方法来完成新的功能，这样写起来简单，但继承体系的可复用性会变差，运用多态特性时，程序运行得到错误结果的可能性很大。如果非要重写父类的方法，可以用其他方式来做：原来的父类和子类都继承一个基类，原有的继承关系去掉，采用依赖、聚合，组合等关系代替。你看这里处理的是继承体系中的变化，对变化的抽象封装。 依赖倒置原则&emsp;&emsp;依赖倒置原则的定义：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。&emsp;&emsp;在面向对象程序编程这个层次来看这个原则就是：面向接口编程。面向接口编程，我们程序就是依赖的接口、没有依赖实现。很好的实现了代码解耦。比如我们常用的Spring框架就是实现了依赖倒置。在Spring框架下编码我们就是面向接口编程了。&emsp;&emsp;依赖倒置原则，不只是代码层面的面向接口编程。在更高层次上面也要遵循这个原则，比如单个系统里面的分层，比如MVC框架使用中，我们要分清楚他们的层级关系，那个是上层，各个层级的依赖要能很好的解耦。包括更高层级的系统和系统之间的依赖。这些都是架构的时候需要结合业务特点来分析好依赖关系，做好解耦处理。 接口隔离原则&emsp;&emsp;接口隔离原则的定义：客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。&emsp;&emsp;前面讲了我们要面向接口编程，那么类之间的依赖、模块之间的依赖、系统之间的依赖都是通过接口来传递依赖关系。上面的接口隔离原则的第一句‘客户端不应该依赖它不需要的接口’,其实就是你暴露给其他模块、其他系统的接口里面只包含他需要的方法。第二句‘一个类对另一个类的依赖应该建立在最小的接口上’，也就是明确说类之间的依赖接口也只包含他需要的方法。其实简单点说，就是不要定义一个很大的接口，里面包括很多的方法。这样的接口就是臃肿的，就像一个类臃肿了，包括了很多功能，责任就不单一了。面对变更修改，会影响很多功能。&emsp;&emsp;是不是觉得接口隔离原则和单一职责原则有点相似呢，不是的。接口隔离主要针对接口定义来说，是对接口约束，接口的设计定义好坏关系到系统间类、模块、系统直接的逻辑内聚和耦合。单一职责强调的是职责，是在不同层级上都可以适用的，所以在接口定义这个层级来说你也是需要考虑单一职责的问题。&emsp;&emsp;接口隔离到底要定义多小的接口，或者多大的接口，这个需要具体业务考虑。不一定是越少越好，越少越好就成了任何接口我就定义一个方法就ok了。永远没有最好的设计，只要能满足当前业务需要和应对后续变化就是很好的了。我们不要犯基础性和常识性的错误，比如为了简单方便，懒得思考设计，定义一个大杂烩接口。 迪米特法则&emsp;&emsp;迪米特法则（Law of Demeter）又叫作最少知道原则（Least Knowledge Principle 简写LKP），就是说一个对象应当对其他对象有尽可能少的了解,不和陌生人说话。&emsp;&emsp;迪米特法则的目的在于降低类之间的耦合，提高类的内聚。比如你定义了一个狗这个类，给这个类定义了一个行走的方法；然后你定义一个人这个类，人去调用狗的行走的方法，指挥狗行走。整个行走的控制都是狗这个类去处理。这个就是符合迪米特法则。但是，如果你行走这个方法不去处理行走功能，而是返回一个狗的腿的对象给人，人来控制狗的腿去行走。那么就违反了迪米特法则。这就是在和陌生人说话了，破坏了高内聚低耦合。 开闭原则&emsp;&emsp;开闭原则的定义：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。&emsp;&emsp;当软件需要变化时，我们是通过扩展实现变化，而不是通过修改已有的代码来实现变化。如果一个软件系统满足开闭原则，那么这个软件就是可复用性好、稳定、高内聚低耦合的。开闭原则是面向对象设计的终极目标，是前面各种准则和各种设计模式运用要到达的目的。我想不可能完全做到对扩展开发和对修改关闭，我们应该以这个目标，无限接近目标。设计模式怎么用&emsp;&emsp;设计模式怎么用呢，是不是把23个模式全部背下来，使用的时候对号入座呢。我想可能没什么用，但是我们还是需要看看23个模式是什么，毕竟是很多年经验的总结。我们开发系统过程中，遇到的各种业务情况，23个模式一定不能全部覆盖搞定。&emsp;&emsp;其实，面相对象设计的核心目的是为了实现系统代码的高内聚、低耦合、封装变化。以上的六个准则基本都是为了解决这三点问题。重点就是要封装变化，怎么才能抽取变化，做好封装，这个也还是需要深入理解业务需求，才能正确的抽取变化。其实除了上面六点原则，还有一点很重要的是“多用组合，少用继承”，组合比继承能更好的封装变化。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://fenghualin.github.io/tags/设计模式/"}]},{"title":"Hello Blog","date":"2018-03-24T09:21:31.000Z","path":"2018/03/24/helloblog/","text":"Hello 博客，我又回来了。分分合合多次了，都怪我没有毅力。这么多年后现在成熟了很多，我要再一次找你回来。这一次在github上给你建立了个人网页，迎接你回来。我也积累了很多的话要和你说，一定要听我给你慢慢道来。相信我一定能坚持下来。 年纪大了，以前很多的事情都没告诉你积累下来，现在都想不起来了，或者以前有记录，但是都记录到其他的乱七八糟的地方，也找不到在什么地方了，连搜索引擎都搜索不到。 从2000年左右你进入中国，都快20年了。虽然现在微博、微信订阅号等很流行。但是blog还是很好的记录文字的地方。并且可以通过微博和微信更广泛的传播。 做了这么多年软件开发，现在我终于发现不断学习新东西和总结过去经验非常重要，用blog来记录学习和经验教训是非常有帮助的。 互联网，软件行业工作流动性很大，说不定哪一天公司挂了，我又要跳槽了，到时候40来岁还要去面试，短暂的面试时间，年轻的面试官可能很难评估出我的能力。那么我把记录在你这里的信息给他看看也许有很大帮助。 我保证，从今以后，我至少两周要给你汇报一次，尽量一周一次。","tags":[{"name":"闲谈","slug":"闲谈","permalink":"https://fenghualin.github.io/tags/闲谈/"}]}]